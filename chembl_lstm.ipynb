{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chembl_lstm.ipynb",
      "provenance": [],
      "mount_file_id": "1A9utstWcG7hjOqAFJPocg2C1JfhUNndx",
      "authorship_tag": "ABX9TyMSAUsDH3t/90feqJ2vZeWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahmida185/NN-Projects/blob/master/chembl_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mo8f8YsfKIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8ad37892-3cfb-4282-a90c-b661826a8437"
      },
      "source": [
        "# load and plot dataset\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from matplotlib import pyplot\n",
        "print(\"Using Tensorflow backend.\")\n",
        "print(\"Reading ChEMB data.\")\n",
        "# load dataset\n",
        "series = read_csv('/content/drive/My Drive/NN_Course/chembl.csv/data.filtered.csv', header=0, index_col=0, squeeze=True)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow backend.\n",
            "Reading ChEMB data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9jp7za_Xg4J",
        "colab_type": "text"
      },
      "source": [
        "An active area of research is the use of neural networks to discover new drugs. In principle we'd like to be able to predict the characteristics of a potential drug without actually measuring the chemical's properties. This would allow much-more rapid development of possible drug candidates, and potentially the ability to discover chemicals with custom properties.\n",
        "\n",
        "Many different approaches to using neural networks to determine a chemical's properties are being studied. Most, if not all, involve analysing chemicals which are represented in \"SMILES\" format. This format represents chemicals as an ASCII string.\n",
        "\n",
        "\n",
        ">>>\n",
        ">>> from rdkit import Chem\n",
        ">>> from rdkit.Chem import Draw\n",
        ">>> import matplotlib.pyplot as plt\n",
        ">>>\n",
        ">>> smiles = \"C1CC2=C3C(=CC=C2)C(=CN3C1)[C@H]4[C@@H](C(=O)NC4=O)C5=CNC6=CC=CC=C65\"\n",
        ">>> chem = Chem.MolFromSmiles(smiles)\n",
        ">>>\n",
        ">>> Draw.MolToMPL(chem, size = (200, 200))\n",
        ">>> plt.show()\n",
        ">>>\n",
        "\n",
        "Suppose we want to design a neural network which would take SMILES-format strings as inputs. The natural way to process these inputs would be to build a recurrent neural network, using LSTMs, which would process the string as a \"sentence\". Once processed, the data could be then used to predict the properties of the chemical.\n",
        "\n",
        "Let us consider a collection of chemicals with annotated nanomolar activities (IC/EC/AC50), which were downloaded from ChEMBL, a database of bioactive molecules. The dataset we will consider can be found here. For this assignment, we will be interested in predicting each chemical's value of the \"AlogP\" column, which is a measure of molecular hydrophobicity (lipophilicity).\n",
        "\n",
        "Create a Python script, called \"chembl_lstm.py\". Your script should:\n",
        "\n",
        "read in the data set and separate out the inputs (the SMILES strings) and targets (the AlogP data),\n",
        "perform whatever preprocessing is necessary to convert the input data into a form that can be used with an LSTM layer,\n",
        "split the data into training and testing data sets,\n",
        "build a neural network, using Keras, to predict the AlogP value, given the input SMILES string.\n",
        "train the network on the training data, and print out the final training loss value,\n",
        "evaluate the network on the test data, and print out the test loss value.\n",
        "Your script will be tested from the Linux command line, thus:\n",
        "\n",
        "$ python chembl_lstm.py\n",
        "Using Tensorflow backend.\n",
        "Reading ChEMB data.\n",
        "Building network.\n",
        "Training network.\n",
        "The training loss is 0.0108\n",
        "The test loss is 0.0195\n",
        "$\n",
        "\n",
        "You do not need to use the full data set (it's quite large), but you should use enough of the data such that overfitting is minimized.\n",
        "\n",
        "The script will be graded on functionality, but also on form.  This means your script should use meaningful variable names and be well commented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0asnDFrhO7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "2cdf7f92-a75a-41d7-9cad-31a2053a9d71"
      },
      "source": [
        "df=series[['Smiles','AlogP']]\n",
        "df.dropna()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    Smiles  AlogP\n",
            "1        CC(=O)Oc1cc(S(=O)(=O)Nc2n[nH]c(Nc3ccc(C)cc3)n2...   3.52\n",
            "2        O=C1N[C@H](c2c[nH]c3cc(Br)ccc23)CN=C1c1c[nH]c2...   4.83\n",
            "3                CCOC(=O)/C=C/C(=O)Nc1cccc([N+](=O)[O-])c1   1.65\n",
            "4                           O=C1Oc2ccccc2/C1=C\\c1ccc(O)cc1   2.85\n",
            "5        COc1c(CO)ccc2oc(C(=O)Nc3ccc(-c4ccc(S(=O)(=O)N[...   4.55\n",
            "...                                                    ...    ...\n",
            "2750108    Clc1ccc(COc2cncc(-c3ccc(CN4CCCCC4)s3)c2)c(Cl)c1   6.68\n",
            "2750111          O=C1c2ccccc2C(=O)c2[nH]c(-c3ccccc3Br)nc21   3.61\n",
            "2750112                CCCN1CCC=C(c2cc(-c3ccc(C)cc3)no2)C1   4.15\n",
            "2750116  CCNC(=O)c1cc2c(-c3cc(C(C)(C)O)ccc3Oc3c(C)cc(F)...   5.06\n",
            "2750118  COc1cc2c(c(OC)n1)[C@]1(O)[C@H](O)[C@H](CN(C)C)...   2.78\n",
            "\n",
            "[909690 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmktohI9gIxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "db32939c-3277-4aa9-f4d9-82ab7ec7c88e"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "import shelve, re\n",
        "# split data into train and test\n",
        "# train data preprocessing\n",
        "train=df['Smiles'].str.strip()\n",
        "trainX=train.str.replace(\"(\",\"\") \n",
        "trainX=trainX.str.replace(\")\",\"\") \n",
        "trainX=trainX.str.replace(\"[\",\"\") \n",
        "trainX=trainX.str.replace(\"]\",\"\") \n",
        "trainX=trainX.str.replace(\"/\",\"\") \n",
        "trainX=trainX.str.replace(\"\\\\\",\"\")\n",
        "trainX=trainX.str.replace(\"+\",\"\")\n",
        "trainX=trainX.str.replace(\"@\",\"\")\n",
        "trainX=trainX.str.replace(\"=\",\"\")\n",
        "trainX=trainX.str.replace(\"-\",\"\")\n",
        "trainX=trainX.str.replace(\"#\",\"\")\n",
        "trainX=trainX.str.lower()\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "\n",
        "train_size = int(len(trainX) * 0.10)\n",
        "test_size = len(trainX) - train_size\n",
        "\n",
        "# binary encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(trainX)\n",
        "train1= integer_encoded\n",
        "train1= train1.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(train1)\n",
        "scaled_X = scaler.transform(train1)\n",
        "\n",
        "train_X= scaled_X[0:train_size]\n",
        "test_X =  scaled_X[train_size:len(scaled_X)]\n",
        "# print(train_X.shape)\n",
        "# print(test_X.shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3qNuqh_ahf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6ab9aee-f957-487f-b83a-05f89031a0e7"
      },
      "source": [
        "# transform Y data \n",
        "test= df['AlogP'].values\n",
        "test= test.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(test)\n",
        "scaled_Y = scaler.transform(test)\n",
        "trainY=scaled_Y\n",
        "\n",
        "ytrain= trainY[0:train_size]\n",
        "ytest =  trainY[train_size:len(trainY)]\n",
        "\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQvhe_E5eOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "140d919f-9df2-4fd7-9dfb-6ba66708d46e"
      },
      "source": [
        "X, y = train_X, ytrain\n",
        "X = X.reshape(X.shape[0],1,1)\n",
        "Xtest= test_X.reshape(test_X.shape[0],1,1)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(Xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1, 1)\n",
            "(90969, 1)\n",
            "(818721, 1, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7STeWOi17BWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "c57cb3c5-6fb1-4aea-d033-05aca6341d6a"
      },
      "source": [
        "print(\"Building network.\")\n",
        "model = km.Sequential()\n",
        "model.add(kl.LSTM(20, activation='tanh', input_shape=(1, 1), return_sequences=True))\n",
        "model.add(kl.Dense(units=20, activation='relu'))\n",
        "model.add(kl.Dense(units=1, activation='linear'))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(\"Training network.\")\n",
        "model.fit(X,y,epochs=20,validation_data=(Xtest,ytest))\n",
        "vy = model.history.history['val_loss']\n",
        "ty = model.history.history['loss']\n",
        "print(\"The training loss is \",ty[-1])\n",
        "print(\"The test loss is \",vy[-1])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building network.\n",
            "Training network.\n",
            "Epoch 1/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0115 - val_loss: 0.0108\n",
            "Epoch 2/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0114 - val_loss: 0.0108\n",
            "Epoch 3/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0114 - val_loss: 0.0107\n",
            "Epoch 4/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 5/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 6/20\n",
            "2843/2843 [==============================] - 28s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 7/20\n",
            "2843/2843 [==============================] - 28s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 8/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 9/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 10/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 11/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 12/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 13/20\n",
            "2843/2843 [==============================] - 31s 11ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 14/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 15/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0113 - val_loss: 0.0108\n",
            "Epoch 16/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 17/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 18/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0112 - val_loss: 0.0108\n",
            "Epoch 19/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0112 - val_loss: 0.0106\n",
            "Epoch 20/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0112 - val_loss: 0.0106\n",
            "The training loss is  0.011239639483392239\n",
            "The test loss is  0.010561738163232803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXkB8FsXenK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMuGVUTcXfjp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rD6ieyANUVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG77dydaMdbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWEP8Ipa6s7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxGk9oWx7AOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zneqi6RspHG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9ZF_uemUbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idcPXH54lq9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    }
  ]
}