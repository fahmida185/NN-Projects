{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chembl_lstm.ipynb",
      "provenance": [],
      "mount_file_id": "1A9utstWcG7hjOqAFJPocg2C1JfhUNndx",
      "authorship_tag": "ABX9TyO/AotTqSbonaXROzIAfGj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahmida185/NN-Projects/blob/master/chembl_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mo8f8YsfKIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0a6ee841-efde-4246-c670-9fb1e986e7e0"
      },
      "source": [
        "# load and plot dataset\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from matplotlib import pyplot\n",
        "print(\"Using Tensorflow backend.\")\n",
        "print(\"Reading ChEMB data.\")\n",
        "# load dataset\n",
        "series = read_csv('/content/drive/My Drive/NN_Course/chembl.csv/data.filtered.csv', header=0, index_col=0, squeeze=True)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow backend.\n",
            "Reading ChEMB data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0asnDFrhO7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "2cdf7f92-a75a-41d7-9cad-31a2053a9d71"
      },
      "source": [
        "df=series[['Smiles','AlogP']]\n",
        "df.dropna()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    Smiles  AlogP\n",
            "1        CC(=O)Oc1cc(S(=O)(=O)Nc2n[nH]c(Nc3ccc(C)cc3)n2...   3.52\n",
            "2        O=C1N[C@H](c2c[nH]c3cc(Br)ccc23)CN=C1c1c[nH]c2...   4.83\n",
            "3                CCOC(=O)/C=C/C(=O)Nc1cccc([N+](=O)[O-])c1   1.65\n",
            "4                           O=C1Oc2ccccc2/C1=C\\c1ccc(O)cc1   2.85\n",
            "5        COc1c(CO)ccc2oc(C(=O)Nc3ccc(-c4ccc(S(=O)(=O)N[...   4.55\n",
            "...                                                    ...    ...\n",
            "2750108    Clc1ccc(COc2cncc(-c3ccc(CN4CCCCC4)s3)c2)c(Cl)c1   6.68\n",
            "2750111          O=C1c2ccccc2C(=O)c2[nH]c(-c3ccccc3Br)nc21   3.61\n",
            "2750112                CCCN1CCC=C(c2cc(-c3ccc(C)cc3)no2)C1   4.15\n",
            "2750116  CCNC(=O)c1cc2c(-c3cc(C(C)(C)O)ccc3Oc3c(C)cc(F)...   5.06\n",
            "2750118  COc1cc2c(c(OC)n1)[C@]1(O)[C@H](O)[C@H](CN(C)C)...   2.78\n",
            "\n",
            "[909690 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmktohI9gIxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "db32939c-3277-4aa9-f4d9-82ab7ec7c88e"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "import shelve, re\n",
        "# split data into train and test\n",
        "# train data preprocessing\n",
        "train=df['Smiles'].str.strip()\n",
        "trainX=train.str.replace(\"(\",\"\") \n",
        "trainX=trainX.str.replace(\")\",\"\") \n",
        "trainX=trainX.str.replace(\"[\",\"\") \n",
        "trainX=trainX.str.replace(\"]\",\"\") \n",
        "trainX=trainX.str.replace(\"/\",\"\") \n",
        "trainX=trainX.str.replace(\"\\\\\",\"\")\n",
        "trainX=trainX.str.replace(\"+\",\"\")\n",
        "trainX=trainX.str.replace(\"@\",\"\")\n",
        "trainX=trainX.str.replace(\"=\",\"\")\n",
        "trainX=trainX.str.replace(\"-\",\"\")\n",
        "trainX=trainX.str.replace(\"#\",\"\")\n",
        "trainX=trainX.str.lower()\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "\n",
        "train_size = int(len(trainX) * 0.10)\n",
        "test_size = len(trainX) - train_size\n",
        "\n",
        "# binary encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(trainX)\n",
        "train1= integer_encoded\n",
        "train1= train1.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(train1)\n",
        "scaled_X = scaler.transform(train1)\n",
        "\n",
        "train_X= scaled_X[0:train_size]\n",
        "test_X =  scaled_X[train_size:len(scaled_X)]\n",
        "# print(train_X.shape)\n",
        "# print(test_X.shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3qNuqh_ahf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6ab9aee-f957-487f-b83a-05f89031a0e7"
      },
      "source": [
        "# transform Y data \n",
        "test= df['AlogP'].values\n",
        "test= test.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(test)\n",
        "scaled_Y = scaler.transform(test)\n",
        "trainY=scaled_Y\n",
        "\n",
        "ytrain= trainY[0:train_size]\n",
        "ytest =  trainY[train_size:len(trainY)]\n",
        "\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQvhe_E5eOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "140d919f-9df2-4fd7-9dfb-6ba66708d46e"
      },
      "source": [
        "X, y = train_X, ytrain\n",
        "X = X.reshape(X.shape[0],1,1)\n",
        "Xtest= test_X.reshape(test_X.shape[0],1,1)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(Xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90969, 1, 1)\n",
            "(90969, 1)\n",
            "(818721, 1, 1)\n",
            "(818721, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7STeWOi17BWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "c57cb3c5-6fb1-4aea-d033-05aca6341d6a"
      },
      "source": [
        "print(\"Building network.\")\n",
        "model = km.Sequential()\n",
        "model.add(kl.LSTM(20, activation='tanh', input_shape=(1, 1), return_sequences=True))\n",
        "model.add(kl.Dense(units=20, activation='relu'))\n",
        "model.add(kl.Dense(units=1, activation='linear'))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(\"Training network.\")\n",
        "model.fit(X,y,epochs=20,validation_data=(Xtest,ytest))\n",
        "vy = model.history.history['val_loss']\n",
        "ty = model.history.history['loss']\n",
        "print(\"The training loss is \",ty[-1])\n",
        "print(\"The test loss is \",vy[-1])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building network.\n",
            "Training network.\n",
            "Epoch 1/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0115 - val_loss: 0.0108\n",
            "Epoch 2/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0114 - val_loss: 0.0108\n",
            "Epoch 3/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0114 - val_loss: 0.0107\n",
            "Epoch 4/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 5/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 6/20\n",
            "2843/2843 [==============================] - 28s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 7/20\n",
            "2843/2843 [==============================] - 28s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 8/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 9/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 10/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 11/20\n",
            "2843/2843 [==============================] - 29s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 12/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 13/20\n",
            "2843/2843 [==============================] - 31s 11ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 14/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 15/20\n",
            "2843/2843 [==============================] - 32s 11ms/step - loss: 0.0113 - val_loss: 0.0108\n",
            "Epoch 16/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 17/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 18/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0112 - val_loss: 0.0108\n",
            "Epoch 19/20\n",
            "2843/2843 [==============================] - 30s 11ms/step - loss: 0.0112 - val_loss: 0.0106\n",
            "Epoch 20/20\n",
            "2843/2843 [==============================] - 30s 10ms/step - loss: 0.0112 - val_loss: 0.0106\n",
            "The training loss is  0.011239639483392239\n",
            "The test loss is  0.010561738163232803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rD6ieyANUVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG77dydaMdbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWEP8Ipa6s7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxGk9oWx7AOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zneqi6RspHG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9ZF_uemUbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idcPXH54lq9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    }
  ]
}