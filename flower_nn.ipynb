{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "flower_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahmida185/NN-Projects/blob/master/flower_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D9IRgBTKiBt",
        "colab_type": "text"
      },
      "source": [
        "# Assignment1\n",
        "\n",
        "Consider the 17 Category Flower Dataset, a modified version of which can be found here, with the associated targets here.  This data set consists of colour images of flowers, each of which is categorized into one of 17 categories. In the modified version of the data set, the images have been scaled to be 50 x 50 pixels each, rather than their original dimensions.\n",
        "\n",
        "This assignment has 2 purposes. The first purpose is to build a neural network which will categorize a given flower image into its respective category.\n",
        "\n",
        "Create a Python script, called \"flower_nn.py\", which performs the following steps:\n",
        "\n",
        "reads in the flower data set, images and targets, given in the links above (the numpy function \"load\" will be helpful here).  You may assume that the files are colocated with the script; the file names may be hard-coded.\n",
        "splits the input and target data into training and testing data sets,\n",
        "builds a neural network, using Keras, to predict the category of the input images,\n",
        "trains the network on the training data, and prints out the final training accuracy,\n",
        "evaluates the network on the test data, and prints out the test accuracy.\n",
        "creates a plot of the model's training loss as a function of epoch.\n",
        "Note that the data has a few details in it which can lead to errors in the implementation of your network, including leading to a failure to train. Be sure to import the data at the Python command line and examine the data carefully, by hand.\n",
        "\n",
        "Your script will be tested from the Linux command line, thus:\n",
        "\n",
        "$ python flowers_nn.py\n",
        "Using Tensorflow backend.\n",
        "Reading flowers input file.\n",
        "Reading flowers target file.\n",
        "Building network.\n",
        "Training network.\n",
        "The training score is [0.291714324566543, 0.9329]\n",
        "The test score is [1.6099461106693043, 0.5845588445663452]\n",
        "$\n",
        "\n",
        "Note that the result above is not an example of a GOOD result. The second part of the assignment is to try to address the problem that this data set has: it's too small. Overfitting is a major problem with the neural networks applied to this data set.\n",
        "\n",
        "For the second part of the assignment, experiment with your script, varying the parameters in your model (number of hidden layers, number of nodes per layer, activation functions, presence/absence of regularization or dropout or batch normalization, cost function, optimization algorithm) to get the model which MINIMIZES OVERFITTING.  You should run the training until the loss stops improving, as demonstrated by your plot. The best model I have found in which the training and testing accuracies are similar returns a training accuracy of about 68% and a test accuracy of 58%.  See if you can do better.\n",
        "\n",
        "The script will be graded on functionality, but also on form.  This means your script should use meaningful variable names and be well commented.\n",
        "\n",
        "Submit your 'flowers_nn.py', and the plot of your training loss, to the 'Assignment Dropbox'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2PQ5zlSKiBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "#######################################################################\n",
        "def get_model(numfm, numnodes, input_shape = (28, 28, 1),\n",
        "              output_size = 10):\n",
        "\n",
        "    \"\"\"\n",
        "    This function returns a convolution neural network Keras model,\n",
        "    with numfm feature maps and numnodes neurons in the\n",
        "    fully-connected layer.\n",
        "\n",
        "    Inputs:\n",
        "    - numfm: int, the number of feature maps in the convolution layer.\n",
        "\n",
        "    - numnodes: int, the number of nodes in the fully-connected layer.\n",
        "\n",
        "    - intput_shape: tuple, the shape of the input data, \n",
        "    default = (28, 28, 1).\n",
        "\n",
        "    - output_size: int, the number of nodes in the output layer,\n",
        "      default = 10.\n",
        "\n",
        "    Output: the constructed Keras model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the model.\n",
        "    model = km.Sequential()\n",
        "\n",
        "    # Add a 2D convolution layer, with numfm feature maps.\n",
        "    model.add(kl.Conv2D(numfm, kernel_size = (5, 5),\n",
        "                        input_shape = input_shape,\n",
        "                        activation = 'relu'))\n",
        "\n",
        "    # Add a max pooling layer.\n",
        "    model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)))\n",
        "\n",
        "    # Convert the network from 2D to 1D.\n",
        "    model.add(kl.Flatten())\n",
        "\n",
        "    # Add a fully-connected layer.\n",
        "    model.add(kl.Dense(numnodes,\n",
        "                       activation = 'tanh'))\n",
        "\n",
        "    # Add the output layer.\n",
        "    model.add(kl.Dense(10, activation = 'softmax'))\n",
        "\n",
        "    # Return the model.\n",
        "    return model\n",
        "\n",
        "#######################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFzeU1N9KiB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "#######################################################################\n",
        "def get_model(numfm, numnodes, input_shape = (28, 28, 1),\n",
        "              output_size = 10):\n",
        "\n",
        "    \"\"\"\n",
        "    This function returns a convolution neural network Keras model,\n",
        "    with numfm feature maps and numnodes neurons in the\n",
        "    fully-connected layer.\n",
        "\n",
        "    Inputs:\n",
        "    - numfm: int, the number of feature maps in the convolution layer.\n",
        "\n",
        "    - numnodes: int, the number of nodes in the fully-connected layer.\n",
        "\n",
        "    - intput_shape: tuple, the shape of the input data, \n",
        "    default = (28, 28, 1).\n",
        "\n",
        "    - output_size: int, the number of nodes in the output layer,\n",
        "      default = 10.\n",
        "\n",
        "    Output: the constructed Keras model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the model.\n",
        "    model = km.Sequential()\n",
        "\n",
        "    # Add a 2D convolution layer, with numfm feature maps.\n",
        "    model.add(kl.Conv2D(numfm, kernel_size = (5, 5),\n",
        "                        input_shape = input_shape,\n",
        "                        activation = 'relu'))\n",
        "\n",
        "    # Add a max pooling layer.\n",
        "    model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)))\n",
        "\n",
        "    # Convert the network from 2D to 1D.\n",
        "    model.add(kl.Flatten())\n",
        "\n",
        "    # Add a fully-connected layer.\n",
        "    model.add(kl.Dense(numnodes,\n",
        "                       activation = 'tanh'))\n",
        "\n",
        "    # Add the output layer.\n",
        "    model.add(kl.Dense(10, activation = 'softmax'))\n",
        "\n",
        "    # Return the model.\n",
        "    return model\n",
        "\n",
        "#######################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qa7nS1IKiB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "061f19a5-5756-4d14-8e86-f9a1d43d5e5c"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import datasets\n",
        "import keras.utils as ku\n",
        "import tensorflow as tf\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "print(\"Using Tensorflow backend.\")\n",
        "IMG_SIZE=50\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,1)\n",
        "numfm=32\n",
        "numnodes=100\n",
        "output_size=17\n",
        "print(\"Reading flowers input file.\")\n",
        "print(\"Reading flowers target file.\")\n",
        "input_data_unprocessed= np.load('/content/sample_data/50x50flowers.images.npy')\n",
        "#input_data_unprocessed= np.load('50x50flowers.images.npy')\n",
        "input_data_processed=[]\n",
        "#target_data= np.load('50x50flowers.targets.npy')\n",
        "target_data= np.load('/content/sample_data/50x50flowers.targets.npy')\n",
        "\n",
        "for i in range(input_data_unprocessed.shape[0]):\n",
        "    grayscale = np.dot(input_data_unprocessed[i], [0.2989, 0.5870, 0.1140])\n",
        "    input_data_processed.append(grayscale)\n",
        "input_data_processed=np.array(input_data_processed)  \n",
        "input_data=input_data_processed\n",
        "target_data=ku.to_categorical(np.asarray(target_data)-1)\n",
        "input_data = input_data.reshape(input_data.shape[0],50,50,1)\n",
        "print(input_data.shape)\n",
        "# input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)\n",
        "# input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow backend.\n",
            "Reading flowers input file.\n",
            "Reading flowers target file.\n",
            "(1360, 50, 50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFPh_Ve_LQz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "946d6e47-cd4b-4e4e-cae0-5cd28e356ff8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TktyePZlDKvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afc03c63-0071-415f-bb4f-f0a1e744d13d"
      },
      "source": [
        "import keras.regularizers as kr\n",
        "import keras.optimizers as op\n",
        "print(\"Building network.\")\n",
        "model1 = km.Sequential()\n",
        "# Add a 2D convolution layer, with numfm feature maps.\n",
        "lam=0.01\n",
        "model1.add(kl.Conv2D(32, kernel_size = (5, 5),\n",
        "                    input_shape = (50,50,1), \n",
        "                    activation = 'relu',name='input'))\n",
        "model1.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.25))\n",
        "\n",
        "model1.add(kl.Conv2D(64, (3, 3),activation='relu'))\n",
        "model1.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.25))\n",
        "\n",
        "model1.add(kl.Dropout(0.25))\n",
        "model1.add(kl.Flatten())\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dense(256, activation='relu'))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.5))\n",
        "model1.add(kl.Dense(17, name = 'output',activation = 'softmax',kernel_regularizer = kr.l2(lam)))\n",
        "\n",
        "model1.output_shape\n",
        "#print(model.summary())\n",
        "model1.compile( optimizer=op.rmsprop(lr=0.01, decay=1e-6), metrics = ['accuracy'], loss = \"categorical_crossentropy\")\n",
        "#print(trainY.shape)\n",
        "print(\"Training network.\") \n",
        "# input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)\n",
        "(trainX, testX, trainY, testY) = train_test_split(input_data, target_data, test_size=0.40)\n",
        "fit = model1.fit(trainX,trainY, epochs = 1000, batch_size = 5, verbose = 2, validation_data=(testX,testY), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - 7s - loss: 0.5117 - accuracy: 0.8799 - val_loss: 3.8583 - val_accuracy: 0.3658\n",
            "Epoch 480/1000\n",
            " - 7s - loss: 0.5471 - accuracy: 0.8738 - val_loss: 4.3323 - val_accuracy: 0.3548\n",
            "Epoch 481/1000\n",
            " - 7s - loss: 0.4822 - accuracy: 0.8750 - val_loss: 3.8064 - val_accuracy: 0.3346\n",
            "Epoch 482/1000\n",
            " - 7s - loss: 0.5682 - accuracy: 0.8689 - val_loss: 4.2578 - val_accuracy: 0.3327\n",
            "Epoch 483/1000\n",
            " - 7s - loss: 0.5032 - accuracy: 0.8934 - val_loss: 4.5641 - val_accuracy: 0.3162\n",
            "Epoch 484/1000\n",
            " - 7s - loss: 0.4902 - accuracy: 0.8811 - val_loss: 4.2222 - val_accuracy: 0.3474\n",
            "Epoch 485/1000\n",
            " - 7s - loss: 0.5225 - accuracy: 0.8701 - val_loss: 4.3220 - val_accuracy: 0.3456\n",
            "Epoch 486/1000\n",
            " - 7s - loss: 0.5042 - accuracy: 0.8836 - val_loss: 4.1665 - val_accuracy: 0.3640\n",
            "Epoch 487/1000\n",
            " - 7s - loss: 0.5962 - accuracy: 0.8566 - val_loss: 4.2973 - val_accuracy: 0.3474\n",
            "Epoch 488/1000\n",
            " - 7s - loss: 0.5139 - accuracy: 0.8824 - val_loss: 4.0383 - val_accuracy: 0.3162\n",
            "Epoch 489/1000\n",
            " - 7s - loss: 0.5026 - accuracy: 0.8848 - val_loss: 4.1034 - val_accuracy: 0.3438\n",
            "Epoch 490/1000\n",
            " - 7s - loss: 0.5015 - accuracy: 0.8873 - val_loss: 4.2201 - val_accuracy: 0.3621\n",
            "Epoch 491/1000\n",
            " - 7s - loss: 0.4791 - accuracy: 0.8934 - val_loss: 3.5881 - val_accuracy: 0.3566\n",
            "Epoch 492/1000\n",
            " - 7s - loss: 0.5775 - accuracy: 0.8529 - val_loss: 4.2922 - val_accuracy: 0.3327\n",
            "Epoch 493/1000\n",
            " - 7s - loss: 0.4767 - accuracy: 0.8873 - val_loss: 4.4042 - val_accuracy: 0.3382\n",
            "Epoch 494/1000\n",
            " - 7s - loss: 0.4363 - accuracy: 0.8934 - val_loss: 4.0374 - val_accuracy: 0.3511\n",
            "Epoch 495/1000\n",
            " - 7s - loss: 0.5888 - accuracy: 0.8615 - val_loss: 4.6059 - val_accuracy: 0.3290\n",
            "Epoch 496/1000\n",
            " - 7s - loss: 0.5000 - accuracy: 0.8860 - val_loss: 4.5495 - val_accuracy: 0.3621\n",
            "Epoch 497/1000\n",
            " - 7s - loss: 0.4641 - accuracy: 0.8946 - val_loss: 4.4143 - val_accuracy: 0.3272\n",
            "Epoch 498/1000\n",
            " - 7s - loss: 0.4806 - accuracy: 0.8873 - val_loss: 4.0417 - val_accuracy: 0.3401\n",
            "Epoch 499/1000\n",
            " - 7s - loss: 0.5326 - accuracy: 0.8750 - val_loss: 4.2002 - val_accuracy: 0.3382\n",
            "Epoch 500/1000\n",
            " - 7s - loss: 0.4665 - accuracy: 0.8934 - val_loss: 3.6416 - val_accuracy: 0.3529\n",
            "Epoch 501/1000\n",
            " - 7s - loss: 0.4831 - accuracy: 0.8860 - val_loss: 3.6834 - val_accuracy: 0.3529\n",
            "Epoch 502/1000\n",
            " - 7s - loss: 0.4684 - accuracy: 0.8860 - val_loss: 3.9294 - val_accuracy: 0.3658\n",
            "Epoch 503/1000\n",
            " - 7s - loss: 0.5140 - accuracy: 0.8885 - val_loss: 4.5246 - val_accuracy: 0.3382\n",
            "Epoch 504/1000\n",
            " - 7s - loss: 0.5440 - accuracy: 0.8762 - val_loss: 4.5375 - val_accuracy: 0.3456\n",
            "Epoch 505/1000\n",
            " - 7s - loss: 0.4591 - accuracy: 0.8971 - val_loss: 3.7307 - val_accuracy: 0.3566\n",
            "Epoch 506/1000\n",
            " - 7s - loss: 0.4966 - accuracy: 0.8897 - val_loss: 4.4976 - val_accuracy: 0.3419\n",
            "Epoch 507/1000\n",
            " - 7s - loss: 0.5536 - accuracy: 0.8713 - val_loss: 3.9018 - val_accuracy: 0.3272\n",
            "Epoch 508/1000\n",
            " - 7s - loss: 0.4771 - accuracy: 0.8971 - val_loss: 5.1971 - val_accuracy: 0.3585\n",
            "Epoch 509/1000\n",
            " - 7s - loss: 0.5506 - accuracy: 0.8701 - val_loss: 4.3417 - val_accuracy: 0.3603\n",
            "Epoch 510/1000\n",
            " - 7s - loss: 0.5181 - accuracy: 0.8762 - val_loss: 5.1607 - val_accuracy: 0.3585\n",
            "Epoch 511/1000\n",
            " - 7s - loss: 0.4909 - accuracy: 0.8762 - val_loss: 4.2397 - val_accuracy: 0.3217\n",
            "Epoch 512/1000\n",
            " - 7s - loss: 0.5077 - accuracy: 0.8799 - val_loss: 4.7434 - val_accuracy: 0.3511\n",
            "Epoch 513/1000\n",
            " - 7s - loss: 0.5000 - accuracy: 0.8909 - val_loss: 3.7137 - val_accuracy: 0.3254\n",
            "Epoch 514/1000\n",
            " - 7s - loss: 0.5153 - accuracy: 0.8738 - val_loss: 4.0255 - val_accuracy: 0.3217\n",
            "Epoch 515/1000\n",
            " - 8s - loss: 0.5192 - accuracy: 0.8713 - val_loss: 4.5489 - val_accuracy: 0.3309\n",
            "Epoch 516/1000\n",
            " - 7s - loss: 0.4666 - accuracy: 0.8934 - val_loss: 3.7765 - val_accuracy: 0.3382\n",
            "Epoch 517/1000\n",
            " - 7s - loss: 0.4278 - accuracy: 0.9032 - val_loss: 4.4002 - val_accuracy: 0.3474\n",
            "Epoch 518/1000\n",
            " - 7s - loss: 0.6190 - accuracy: 0.8456 - val_loss: 3.8760 - val_accuracy: 0.3621\n",
            "Epoch 519/1000\n",
            " - 7s - loss: 0.5094 - accuracy: 0.8713 - val_loss: 4.4012 - val_accuracy: 0.3254\n",
            "Epoch 520/1000\n",
            " - 7s - loss: 0.5123 - accuracy: 0.8860 - val_loss: 5.9456 - val_accuracy: 0.3272\n",
            "Epoch 521/1000\n",
            " - 7s - loss: 0.5769 - accuracy: 0.8640 - val_loss: 3.7663 - val_accuracy: 0.3511\n",
            "Epoch 522/1000\n",
            " - 7s - loss: 0.4397 - accuracy: 0.8958 - val_loss: 3.8271 - val_accuracy: 0.3548\n",
            "Epoch 523/1000\n",
            " - 7s - loss: 0.4995 - accuracy: 0.8836 - val_loss: 3.9070 - val_accuracy: 0.3272\n",
            "Epoch 524/1000\n",
            " - 7s - loss: 0.5731 - accuracy: 0.8689 - val_loss: 4.8155 - val_accuracy: 0.3493\n",
            "Epoch 525/1000\n",
            " - 7s - loss: 0.4388 - accuracy: 0.8922 - val_loss: 4.3959 - val_accuracy: 0.3456\n",
            "Epoch 526/1000\n",
            " - 7s - loss: 0.4570 - accuracy: 0.8922 - val_loss: 3.8173 - val_accuracy: 0.3511\n",
            "Epoch 527/1000\n",
            " - 7s - loss: 0.4393 - accuracy: 0.8787 - val_loss: 4.3866 - val_accuracy: 0.3511\n",
            "Epoch 528/1000\n",
            " - 7s - loss: 0.5396 - accuracy: 0.8689 - val_loss: 4.8100 - val_accuracy: 0.3456\n",
            "Epoch 529/1000\n",
            " - 7s - loss: 0.5223 - accuracy: 0.8738 - val_loss: 4.3828 - val_accuracy: 0.3456\n",
            "Epoch 530/1000\n",
            " - 7s - loss: 0.5129 - accuracy: 0.8885 - val_loss: 3.7014 - val_accuracy: 0.3768\n",
            "Epoch 531/1000\n",
            " - 7s - loss: 0.5126 - accuracy: 0.8836 - val_loss: 4.4666 - val_accuracy: 0.3548\n",
            "Epoch 532/1000\n",
            " - 7s - loss: 0.4837 - accuracy: 0.8909 - val_loss: 4.5858 - val_accuracy: 0.3309\n",
            "Epoch 533/1000\n",
            " - 7s - loss: 0.5067 - accuracy: 0.8958 - val_loss: 3.5951 - val_accuracy: 0.3621\n",
            "Epoch 534/1000\n",
            " - 7s - loss: 0.5362 - accuracy: 0.8542 - val_loss: 4.1788 - val_accuracy: 0.3511\n",
            "Epoch 535/1000\n",
            " - 7s - loss: 0.4256 - accuracy: 0.8971 - val_loss: 5.2606 - val_accuracy: 0.3438\n",
            "Epoch 536/1000\n",
            " - 7s - loss: 0.5392 - accuracy: 0.8860 - val_loss: 4.1582 - val_accuracy: 0.3658\n",
            "Epoch 537/1000\n",
            " - 7s - loss: 0.5165 - accuracy: 0.8713 - val_loss: 5.7897 - val_accuracy: 0.3364\n",
            "Epoch 538/1000\n",
            " - 7s - loss: 0.5518 - accuracy: 0.8848 - val_loss: 4.7270 - val_accuracy: 0.3162\n",
            "Epoch 539/1000\n",
            " - 7s - loss: 0.5286 - accuracy: 0.8738 - val_loss: 4.4165 - val_accuracy: 0.3511\n",
            "Epoch 540/1000\n",
            " - 7s - loss: 0.4200 - accuracy: 0.8971 - val_loss: 4.0569 - val_accuracy: 0.3621\n",
            "Epoch 541/1000\n",
            " - 7s - loss: 0.4620 - accuracy: 0.9007 - val_loss: 3.6199 - val_accuracy: 0.3676\n",
            "Epoch 542/1000\n",
            " - 7s - loss: 0.5914 - accuracy: 0.8554 - val_loss: 4.3913 - val_accuracy: 0.3364\n",
            "Epoch 543/1000\n",
            " - 7s - loss: 0.4494 - accuracy: 0.8897 - val_loss: 3.5685 - val_accuracy: 0.3566\n",
            "Epoch 544/1000\n",
            " - 7s - loss: 0.4851 - accuracy: 0.8725 - val_loss: 4.4424 - val_accuracy: 0.3327\n",
            "Epoch 545/1000\n",
            " - 7s - loss: 0.5299 - accuracy: 0.8701 - val_loss: 4.7326 - val_accuracy: 0.3438\n",
            "Epoch 546/1000\n",
            " - 7s - loss: 0.4447 - accuracy: 0.8897 - val_loss: 3.7989 - val_accuracy: 0.3732\n",
            "Epoch 547/1000\n",
            " - 7s - loss: 0.6277 - accuracy: 0.8542 - val_loss: 3.8292 - val_accuracy: 0.3585\n",
            "Epoch 548/1000\n",
            " - 7s - loss: 0.4775 - accuracy: 0.8873 - val_loss: 3.6194 - val_accuracy: 0.3603\n",
            "Epoch 549/1000\n",
            " - 7s - loss: 0.4876 - accuracy: 0.8848 - val_loss: 5.4093 - val_accuracy: 0.3548\n",
            "Epoch 550/1000\n",
            " - 7s - loss: 0.4529 - accuracy: 0.8946 - val_loss: 3.8791 - val_accuracy: 0.3474\n",
            "Epoch 551/1000\n",
            " - 7s - loss: 0.5086 - accuracy: 0.8762 - val_loss: 3.9668 - val_accuracy: 0.3511\n",
            "Epoch 552/1000\n",
            " - 7s - loss: 0.5170 - accuracy: 0.8848 - val_loss: 4.0777 - val_accuracy: 0.3346\n",
            "Epoch 553/1000\n",
            " - 7s - loss: 0.4884 - accuracy: 0.8860 - val_loss: 3.7479 - val_accuracy: 0.3474\n",
            "Epoch 554/1000\n",
            " - 7s - loss: 0.4840 - accuracy: 0.8848 - val_loss: 3.7506 - val_accuracy: 0.3419\n",
            "Epoch 555/1000\n",
            " - 7s - loss: 0.4607 - accuracy: 0.8946 - val_loss: 5.1783 - val_accuracy: 0.3658\n",
            "Epoch 556/1000\n",
            " - 7s - loss: 0.4336 - accuracy: 0.9032 - val_loss: 4.4937 - val_accuracy: 0.3640\n",
            "Epoch 557/1000\n",
            " - 7s - loss: 0.4897 - accuracy: 0.8922 - val_loss: 3.6168 - val_accuracy: 0.3695\n",
            "Epoch 558/1000\n",
            " - 7s - loss: 0.5360 - accuracy: 0.8713 - val_loss: 3.7518 - val_accuracy: 0.3621\n",
            "Epoch 559/1000\n",
            " - 7s - loss: 0.4946 - accuracy: 0.8934 - val_loss: 4.1977 - val_accuracy: 0.3640\n",
            "Epoch 560/1000\n",
            " - 7s - loss: 0.5068 - accuracy: 0.8824 - val_loss: 4.6433 - val_accuracy: 0.3511\n",
            "Epoch 561/1000\n",
            " - 7s - loss: 0.4560 - accuracy: 0.8873 - val_loss: 3.9376 - val_accuracy: 0.3676\n",
            "Epoch 562/1000\n",
            " - 7s - loss: 0.5602 - accuracy: 0.8738 - val_loss: 5.4779 - val_accuracy: 0.3235\n",
            "Epoch 563/1000\n",
            " - 7s - loss: 0.4388 - accuracy: 0.8971 - val_loss: 3.8689 - val_accuracy: 0.3621\n",
            "Epoch 564/1000\n",
            " - 7s - loss: 0.4624 - accuracy: 0.8946 - val_loss: 3.6526 - val_accuracy: 0.3474\n",
            "Epoch 565/1000\n",
            " - 7s - loss: 0.3758 - accuracy: 0.9130 - val_loss: 4.0210 - val_accuracy: 0.3640\n",
            "Epoch 566/1000\n",
            " - 7s - loss: 0.4765 - accuracy: 0.8934 - val_loss: 4.2897 - val_accuracy: 0.3566\n",
            "Epoch 567/1000\n",
            " - 7s - loss: 0.4652 - accuracy: 0.8922 - val_loss: 4.7752 - val_accuracy: 0.3162\n",
            "Epoch 568/1000\n",
            " - 7s - loss: 0.4906 - accuracy: 0.8909 - val_loss: 3.7543 - val_accuracy: 0.3842\n",
            "Epoch 569/1000\n",
            " - 7s - loss: 0.4284 - accuracy: 0.8934 - val_loss: 4.3082 - val_accuracy: 0.3290\n",
            "Epoch 570/1000\n",
            " - 7s - loss: 0.4758 - accuracy: 0.8946 - val_loss: 5.0522 - val_accuracy: 0.3419\n",
            "Epoch 571/1000\n",
            " - 7s - loss: 0.4667 - accuracy: 0.8811 - val_loss: 4.2781 - val_accuracy: 0.3382\n",
            "Epoch 572/1000\n",
            " - 7s - loss: 0.4983 - accuracy: 0.8873 - val_loss: 4.4355 - val_accuracy: 0.3621\n",
            "Epoch 573/1000\n",
            " - 7s - loss: 0.5873 - accuracy: 0.8701 - val_loss: 5.1524 - val_accuracy: 0.3419\n",
            "Epoch 574/1000\n",
            " - 7s - loss: 0.4885 - accuracy: 0.8922 - val_loss: 5.1800 - val_accuracy: 0.3309\n",
            "Epoch 575/1000\n",
            " - 7s - loss: 0.5283 - accuracy: 0.8836 - val_loss: 4.1202 - val_accuracy: 0.3603\n",
            "Epoch 576/1000\n",
            " - 7s - loss: 0.4406 - accuracy: 0.8934 - val_loss: 4.1087 - val_accuracy: 0.3676\n",
            "Epoch 577/1000\n",
            " - 7s - loss: 0.5040 - accuracy: 0.8873 - val_loss: 5.2593 - val_accuracy: 0.3290\n",
            "Epoch 578/1000\n",
            " - 7s - loss: 0.5036 - accuracy: 0.8836 - val_loss: 4.6725 - val_accuracy: 0.3382\n",
            "Epoch 579/1000\n",
            " - 7s - loss: 0.4903 - accuracy: 0.8934 - val_loss: 4.0789 - val_accuracy: 0.3511\n",
            "Epoch 580/1000\n",
            " - 7s - loss: 0.5069 - accuracy: 0.8848 - val_loss: 4.0102 - val_accuracy: 0.3217\n",
            "Epoch 581/1000\n",
            " - 7s - loss: 0.5440 - accuracy: 0.8922 - val_loss: 4.5218 - val_accuracy: 0.3438\n",
            "Epoch 582/1000\n",
            " - 7s - loss: 0.4378 - accuracy: 0.8971 - val_loss: 4.5018 - val_accuracy: 0.3382\n",
            "Epoch 583/1000\n",
            " - 7s - loss: 0.4595 - accuracy: 0.8958 - val_loss: 4.2899 - val_accuracy: 0.3290\n",
            "Epoch 584/1000\n",
            " - 7s - loss: 0.5155 - accuracy: 0.8860 - val_loss: 4.0828 - val_accuracy: 0.3529\n",
            "Epoch 585/1000\n",
            " - 7s - loss: 0.4027 - accuracy: 0.9142 - val_loss: 4.5314 - val_accuracy: 0.3529\n",
            "Epoch 586/1000\n",
            " - 7s - loss: 0.4690 - accuracy: 0.8983 - val_loss: 4.7144 - val_accuracy: 0.3438\n",
            "Epoch 587/1000\n",
            " - 7s - loss: 0.4750 - accuracy: 0.8811 - val_loss: 4.3739 - val_accuracy: 0.3456\n",
            "Epoch 588/1000\n",
            " - 7s - loss: 0.4864 - accuracy: 0.8946 - val_loss: 4.2237 - val_accuracy: 0.3640\n",
            "Epoch 589/1000\n",
            " - 7s - loss: 0.4965 - accuracy: 0.8934 - val_loss: 4.9583 - val_accuracy: 0.3272\n",
            "Epoch 590/1000\n",
            " - 7s - loss: 0.4867 - accuracy: 0.8909 - val_loss: 4.3341 - val_accuracy: 0.3621\n",
            "Epoch 591/1000\n",
            " - 7s - loss: 0.4656 - accuracy: 0.8946 - val_loss: 3.7150 - val_accuracy: 0.3603\n",
            "Epoch 592/1000\n",
            " - 7s - loss: 0.4712 - accuracy: 0.8897 - val_loss: 5.4507 - val_accuracy: 0.3603\n",
            "Epoch 593/1000\n",
            " - 7s - loss: 0.4847 - accuracy: 0.8873 - val_loss: 4.6210 - val_accuracy: 0.3658\n",
            "Epoch 594/1000\n",
            " - 7s - loss: 0.4804 - accuracy: 0.8848 - val_loss: 4.2587 - val_accuracy: 0.3529\n",
            "Epoch 595/1000\n",
            " - 7s - loss: 0.5509 - accuracy: 0.8811 - val_loss: 4.5135 - val_accuracy: 0.3438\n",
            "Epoch 596/1000\n",
            " - 7s - loss: 0.5524 - accuracy: 0.8873 - val_loss: 4.1731 - val_accuracy: 0.3493\n",
            "Epoch 597/1000\n",
            " - 7s - loss: 0.5230 - accuracy: 0.8676 - val_loss: 4.9673 - val_accuracy: 0.3419\n",
            "Epoch 598/1000\n",
            " - 7s - loss: 0.4758 - accuracy: 0.8971 - val_loss: 4.0412 - val_accuracy: 0.3529\n",
            "Epoch 599/1000\n",
            " - 7s - loss: 0.4368 - accuracy: 0.8971 - val_loss: 4.8285 - val_accuracy: 0.3382\n",
            "Epoch 600/1000\n",
            " - 7s - loss: 0.5298 - accuracy: 0.8824 - val_loss: 4.7609 - val_accuracy: 0.3235\n",
            "Epoch 601/1000\n",
            " - 7s - loss: 0.4682 - accuracy: 0.8836 - val_loss: 3.6645 - val_accuracy: 0.3732\n",
            "Epoch 602/1000\n",
            " - 7s - loss: 0.5398 - accuracy: 0.8824 - val_loss: 4.6145 - val_accuracy: 0.3309\n",
            "Epoch 603/1000\n",
            " - 7s - loss: 0.5272 - accuracy: 0.8725 - val_loss: 4.9211 - val_accuracy: 0.3327\n",
            "Epoch 604/1000\n",
            " - 7s - loss: 0.5506 - accuracy: 0.8860 - val_loss: 4.4807 - val_accuracy: 0.3640\n",
            "Epoch 605/1000\n",
            " - 7s - loss: 0.3988 - accuracy: 0.9056 - val_loss: 4.3828 - val_accuracy: 0.3548\n",
            "Epoch 606/1000\n",
            " - 7s - loss: 0.4617 - accuracy: 0.8983 - val_loss: 3.9959 - val_accuracy: 0.3585\n",
            "Epoch 607/1000\n",
            " - 7s - loss: 0.5098 - accuracy: 0.8873 - val_loss: 4.0260 - val_accuracy: 0.3474\n",
            "Epoch 608/1000\n",
            " - 7s - loss: 0.3940 - accuracy: 0.9032 - val_loss: 4.2784 - val_accuracy: 0.3474\n",
            "Epoch 609/1000\n",
            " - 7s - loss: 0.4711 - accuracy: 0.8934 - val_loss: 4.0739 - val_accuracy: 0.3529\n",
            "Epoch 610/1000\n",
            " - 7s - loss: 0.4849 - accuracy: 0.8775 - val_loss: 4.8733 - val_accuracy: 0.3548\n",
            "Epoch 611/1000\n",
            " - 7s - loss: 0.4365 - accuracy: 0.8934 - val_loss: 5.0394 - val_accuracy: 0.3566\n",
            "Epoch 612/1000\n",
            " - 7s - loss: 0.4513 - accuracy: 0.8995 - val_loss: 4.4110 - val_accuracy: 0.3493\n",
            "Epoch 613/1000\n",
            " - 7s - loss: 0.4477 - accuracy: 0.8885 - val_loss: 4.2208 - val_accuracy: 0.3493\n",
            "Epoch 614/1000\n",
            " - 7s - loss: 0.4836 - accuracy: 0.8836 - val_loss: 4.7647 - val_accuracy: 0.3621\n",
            "Epoch 615/1000\n",
            " - 7s - loss: 0.4617 - accuracy: 0.8971 - val_loss: 4.2205 - val_accuracy: 0.3217\n",
            "Epoch 616/1000\n",
            " - 7s - loss: 0.4720 - accuracy: 0.8971 - val_loss: 4.1932 - val_accuracy: 0.3419\n",
            "Epoch 617/1000\n",
            " - 7s - loss: 0.5060 - accuracy: 0.8664 - val_loss: 4.3062 - val_accuracy: 0.3603\n",
            "Epoch 618/1000\n",
            " - 7s - loss: 0.3844 - accuracy: 0.9105 - val_loss: 4.0361 - val_accuracy: 0.3493\n",
            "Epoch 619/1000\n",
            " - 7s - loss: 0.4532 - accuracy: 0.8971 - val_loss: 4.9247 - val_accuracy: 0.3585\n",
            "Epoch 620/1000\n",
            " - 7s - loss: 0.5573 - accuracy: 0.8640 - val_loss: 4.4702 - val_accuracy: 0.3621\n",
            "Epoch 621/1000\n",
            " - 7s - loss: 0.4358 - accuracy: 0.8995 - val_loss: 4.0607 - val_accuracy: 0.3529\n",
            "Epoch 622/1000\n",
            " - 7s - loss: 0.4371 - accuracy: 0.8946 - val_loss: 4.3852 - val_accuracy: 0.3419\n",
            "Epoch 623/1000\n",
            " - 7s - loss: 0.4286 - accuracy: 0.9020 - val_loss: 4.5493 - val_accuracy: 0.3456\n",
            "Epoch 624/1000\n",
            " - 7s - loss: 0.5776 - accuracy: 0.8750 - val_loss: 4.2497 - val_accuracy: 0.3511\n",
            "Epoch 625/1000\n",
            " - 7s - loss: 0.5432 - accuracy: 0.8725 - val_loss: 5.0613 - val_accuracy: 0.2923\n",
            "Epoch 626/1000\n",
            " - 7s - loss: 0.5621 - accuracy: 0.8713 - val_loss: 5.7770 - val_accuracy: 0.3364\n",
            "Epoch 627/1000\n",
            " - 7s - loss: 0.4584 - accuracy: 0.8873 - val_loss: 5.6254 - val_accuracy: 0.3401\n",
            "Epoch 628/1000\n",
            " - 7s - loss: 0.4386 - accuracy: 0.8946 - val_loss: 4.6375 - val_accuracy: 0.3713\n",
            "Epoch 629/1000\n",
            " - 7s - loss: 0.4234 - accuracy: 0.9044 - val_loss: 3.9046 - val_accuracy: 0.3566\n",
            "Epoch 630/1000\n",
            " - 7s - loss: 0.4688 - accuracy: 0.8897 - val_loss: 4.6801 - val_accuracy: 0.3676\n",
            "Epoch 631/1000\n",
            " - 7s - loss: 0.4119 - accuracy: 0.9069 - val_loss: 4.2724 - val_accuracy: 0.3327\n",
            "Epoch 632/1000\n",
            " - 7s - loss: 0.4989 - accuracy: 0.8836 - val_loss: 4.3574 - val_accuracy: 0.3805\n",
            "Epoch 633/1000\n",
            " - 7s - loss: 0.5146 - accuracy: 0.8836 - val_loss: 4.7569 - val_accuracy: 0.3364\n",
            "Epoch 634/1000\n",
            " - 7s - loss: 0.4956 - accuracy: 0.8873 - val_loss: 5.3984 - val_accuracy: 0.3364\n",
            "Epoch 635/1000\n",
            " - 8s - loss: 0.4322 - accuracy: 0.9044 - val_loss: 3.9030 - val_accuracy: 0.3474\n",
            "Epoch 636/1000\n",
            " - 9s - loss: 0.4018 - accuracy: 0.9020 - val_loss: 4.7658 - val_accuracy: 0.3474\n",
            "Epoch 637/1000\n",
            " - 9s - loss: 0.4273 - accuracy: 0.8958 - val_loss: 3.9421 - val_accuracy: 0.3585\n",
            "Epoch 638/1000\n",
            " - 7s - loss: 0.5694 - accuracy: 0.8701 - val_loss: 4.5079 - val_accuracy: 0.3658\n",
            "Epoch 639/1000\n",
            " - 7s - loss: 0.4322 - accuracy: 0.9093 - val_loss: 3.7398 - val_accuracy: 0.3566\n",
            "Epoch 640/1000\n",
            " - 7s - loss: 0.4506 - accuracy: 0.9007 - val_loss: 4.6581 - val_accuracy: 0.3456\n",
            "Epoch 641/1000\n",
            " - 7s - loss: 0.4204 - accuracy: 0.9032 - val_loss: 4.5280 - val_accuracy: 0.3456\n",
            "Epoch 642/1000\n",
            " - 8s - loss: 0.3861 - accuracy: 0.9118 - val_loss: 5.2459 - val_accuracy: 0.3805\n",
            "Epoch 643/1000\n",
            " - 8s - loss: 0.5043 - accuracy: 0.8811 - val_loss: 4.0747 - val_accuracy: 0.3585\n",
            "Epoch 644/1000\n",
            " - 7s - loss: 0.4158 - accuracy: 0.8983 - val_loss: 4.9890 - val_accuracy: 0.3621\n",
            "Epoch 645/1000\n",
            " - 7s - loss: 0.4352 - accuracy: 0.9032 - val_loss: 4.3295 - val_accuracy: 0.3511\n",
            "Epoch 646/1000\n",
            " - 7s - loss: 0.5157 - accuracy: 0.8775 - val_loss: 4.0412 - val_accuracy: 0.3566\n",
            "Epoch 647/1000\n",
            " - 7s - loss: 0.4624 - accuracy: 0.8934 - val_loss: 3.7279 - val_accuracy: 0.3401\n",
            "Epoch 648/1000\n",
            " - 7s - loss: 0.5055 - accuracy: 0.8848 - val_loss: 3.7080 - val_accuracy: 0.3713\n",
            "Epoch 649/1000\n",
            " - 7s - loss: 0.4234 - accuracy: 0.9032 - val_loss: 3.7961 - val_accuracy: 0.3438\n",
            "Epoch 650/1000\n",
            " - 7s - loss: 0.4602 - accuracy: 0.9069 - val_loss: 4.0290 - val_accuracy: 0.3438\n",
            "Epoch 651/1000\n",
            " - 7s - loss: 0.4613 - accuracy: 0.8897 - val_loss: 4.4069 - val_accuracy: 0.3162\n",
            "Epoch 652/1000\n",
            " - 7s - loss: 0.4341 - accuracy: 0.8995 - val_loss: 4.4043 - val_accuracy: 0.3493\n",
            "Epoch 653/1000\n",
            " - 7s - loss: 0.5036 - accuracy: 0.8885 - val_loss: 4.5000 - val_accuracy: 0.3474\n",
            "Epoch 654/1000\n",
            " - 7s - loss: 0.5207 - accuracy: 0.8909 - val_loss: 4.7315 - val_accuracy: 0.3217\n",
            "Epoch 655/1000\n",
            " - 7s - loss: 0.4197 - accuracy: 0.9007 - val_loss: 4.9677 - val_accuracy: 0.3548\n",
            "Epoch 656/1000\n",
            " - 7s - loss: 0.5283 - accuracy: 0.8873 - val_loss: 3.9275 - val_accuracy: 0.3695\n",
            "Epoch 657/1000\n",
            " - 7s - loss: 0.4892 - accuracy: 0.8983 - val_loss: 3.9287 - val_accuracy: 0.3824\n",
            "Epoch 658/1000\n",
            " - 7s - loss: 0.4340 - accuracy: 0.8934 - val_loss: 4.5302 - val_accuracy: 0.3529\n",
            "Epoch 659/1000\n",
            " - 7s - loss: 0.4361 - accuracy: 0.8958 - val_loss: 5.2378 - val_accuracy: 0.3199\n",
            "Epoch 660/1000\n",
            " - 7s - loss: 0.4573 - accuracy: 0.8934 - val_loss: 4.0321 - val_accuracy: 0.3401\n",
            "Epoch 661/1000\n",
            " - 7s - loss: 0.5147 - accuracy: 0.8860 - val_loss: 4.2953 - val_accuracy: 0.3566\n",
            "Epoch 662/1000\n",
            " - 7s - loss: 0.3999 - accuracy: 0.9020 - val_loss: 3.6679 - val_accuracy: 0.3787\n",
            "Epoch 663/1000\n",
            " - 7s - loss: 0.4494 - accuracy: 0.9044 - val_loss: 4.0647 - val_accuracy: 0.3860\n",
            "Epoch 664/1000\n",
            " - 7s - loss: 0.5142 - accuracy: 0.8885 - val_loss: 4.3775 - val_accuracy: 0.3934\n",
            "Epoch 665/1000\n",
            " - 7s - loss: 0.5249 - accuracy: 0.8848 - val_loss: 4.2369 - val_accuracy: 0.3511\n",
            "Epoch 666/1000\n",
            " - 7s - loss: 0.4990 - accuracy: 0.8885 - val_loss: 4.8877 - val_accuracy: 0.3860\n",
            "Epoch 667/1000\n",
            " - 7s - loss: 0.4214 - accuracy: 0.9020 - val_loss: 4.7575 - val_accuracy: 0.3511\n",
            "Epoch 668/1000\n",
            " - 7s - loss: 0.4454 - accuracy: 0.8909 - val_loss: 4.3220 - val_accuracy: 0.3585\n",
            "Epoch 669/1000\n",
            " - 7s - loss: 0.4688 - accuracy: 0.8897 - val_loss: 4.3174 - val_accuracy: 0.3548\n",
            "Epoch 670/1000\n",
            " - 7s - loss: 0.4057 - accuracy: 0.8983 - val_loss: 4.6112 - val_accuracy: 0.3548\n",
            "Epoch 671/1000\n",
            " - 7s - loss: 0.4861 - accuracy: 0.8836 - val_loss: 4.3158 - val_accuracy: 0.3603\n",
            "Epoch 672/1000\n",
            " - 7s - loss: 0.4874 - accuracy: 0.8909 - val_loss: 4.7580 - val_accuracy: 0.3640\n",
            "Epoch 673/1000\n",
            " - 7s - loss: 0.4913 - accuracy: 0.8860 - val_loss: 4.8059 - val_accuracy: 0.3640\n",
            "Epoch 674/1000\n",
            " - 7s - loss: 0.4820 - accuracy: 0.8873 - val_loss: 4.3074 - val_accuracy: 0.3235\n",
            "Epoch 675/1000\n",
            " - 7s - loss: 0.3974 - accuracy: 0.9154 - val_loss: 4.5412 - val_accuracy: 0.3438\n",
            "Epoch 676/1000\n",
            " - 8s - loss: 0.4431 - accuracy: 0.8934 - val_loss: 3.8860 - val_accuracy: 0.3621\n",
            "Epoch 677/1000\n",
            " - 7s - loss: 0.4161 - accuracy: 0.9093 - val_loss: 4.4948 - val_accuracy: 0.3566\n",
            "Epoch 678/1000\n",
            " - 7s - loss: 0.4393 - accuracy: 0.8946 - val_loss: 5.4970 - val_accuracy: 0.3566\n",
            "Epoch 679/1000\n",
            " - 7s - loss: 0.4234 - accuracy: 0.9020 - val_loss: 4.6917 - val_accuracy: 0.3474\n",
            "Epoch 680/1000\n",
            " - 7s - loss: 0.4722 - accuracy: 0.9007 - val_loss: 5.5970 - val_accuracy: 0.3290\n",
            "Epoch 681/1000\n",
            " - 7s - loss: 0.3717 - accuracy: 0.9069 - val_loss: 5.8094 - val_accuracy: 0.3603\n",
            "Epoch 682/1000\n",
            " - 7s - loss: 0.3815 - accuracy: 0.9228 - val_loss: 4.2085 - val_accuracy: 0.3768\n",
            "Epoch 683/1000\n",
            " - 7s - loss: 0.5189 - accuracy: 0.8750 - val_loss: 4.1514 - val_accuracy: 0.3474\n",
            "Epoch 684/1000\n",
            " - 8s - loss: 0.4233 - accuracy: 0.9130 - val_loss: 4.2335 - val_accuracy: 0.3419\n",
            "Epoch 685/1000\n",
            " - 8s - loss: 0.4154 - accuracy: 0.9020 - val_loss: 5.0976 - val_accuracy: 0.3309\n",
            "Epoch 686/1000\n",
            " - 8s - loss: 0.4817 - accuracy: 0.8946 - val_loss: 5.6356 - val_accuracy: 0.3199\n",
            "Epoch 687/1000\n",
            " - 7s - loss: 0.4537 - accuracy: 0.8897 - val_loss: 5.8348 - val_accuracy: 0.3493\n",
            "Epoch 688/1000\n",
            " - 7s - loss: 0.4762 - accuracy: 0.8909 - val_loss: 4.1380 - val_accuracy: 0.3566\n",
            "Epoch 689/1000\n",
            " - 7s - loss: 0.4490 - accuracy: 0.9007 - val_loss: 4.7145 - val_accuracy: 0.3474\n",
            "Epoch 690/1000\n",
            " - 7s - loss: 0.4868 - accuracy: 0.8775 - val_loss: 4.8433 - val_accuracy: 0.3051\n",
            "Epoch 691/1000\n",
            " - 7s - loss: 0.4145 - accuracy: 0.9032 - val_loss: 5.2835 - val_accuracy: 0.3566\n",
            "Epoch 692/1000\n",
            " - 7s - loss: 0.4582 - accuracy: 0.8946 - val_loss: 5.1293 - val_accuracy: 0.3493\n",
            "Epoch 693/1000\n",
            " - 7s - loss: 0.4517 - accuracy: 0.9007 - val_loss: 4.4135 - val_accuracy: 0.3364\n",
            "Epoch 694/1000\n",
            " - 7s - loss: 0.4481 - accuracy: 0.9007 - val_loss: 4.9193 - val_accuracy: 0.3419\n",
            "Epoch 695/1000\n",
            " - 7s - loss: 0.4650 - accuracy: 0.8885 - val_loss: 4.2409 - val_accuracy: 0.3621\n",
            "Epoch 696/1000\n",
            " - 7s - loss: 0.5009 - accuracy: 0.8909 - val_loss: 4.3863 - val_accuracy: 0.3401\n",
            "Epoch 697/1000\n",
            " - 7s - loss: 0.4212 - accuracy: 0.8971 - val_loss: 4.9328 - val_accuracy: 0.3676\n",
            "Epoch 698/1000\n",
            " - 7s - loss: 0.4223 - accuracy: 0.9056 - val_loss: 4.2424 - val_accuracy: 0.3658\n",
            "Epoch 699/1000\n",
            " - 7s - loss: 0.4981 - accuracy: 0.8836 - val_loss: 4.4478 - val_accuracy: 0.3290\n",
            "Epoch 700/1000\n",
            " - 7s - loss: 0.4669 - accuracy: 0.8922 - val_loss: 5.2540 - val_accuracy: 0.3732\n",
            "Epoch 701/1000\n",
            " - 7s - loss: 0.5174 - accuracy: 0.8873 - val_loss: 4.4300 - val_accuracy: 0.3695\n",
            "Epoch 702/1000\n",
            " - 7s - loss: 0.5185 - accuracy: 0.8848 - val_loss: 3.9636 - val_accuracy: 0.3603\n",
            "Epoch 703/1000\n",
            " - 7s - loss: 0.5006 - accuracy: 0.8762 - val_loss: 4.1470 - val_accuracy: 0.3548\n",
            "Epoch 704/1000\n",
            " - 7s - loss: 0.4509 - accuracy: 0.8995 - val_loss: 3.8719 - val_accuracy: 0.3640\n",
            "Epoch 705/1000\n",
            " - 7s - loss: 0.4443 - accuracy: 0.8934 - val_loss: 4.8969 - val_accuracy: 0.3621\n",
            "Epoch 706/1000\n",
            " - 7s - loss: 0.4827 - accuracy: 0.8909 - val_loss: 4.0935 - val_accuracy: 0.3419\n",
            "Epoch 707/1000\n",
            " - 7s - loss: 0.4180 - accuracy: 0.9044 - val_loss: 4.9986 - val_accuracy: 0.3824\n",
            "Epoch 708/1000\n",
            " - 7s - loss: 0.4217 - accuracy: 0.9069 - val_loss: 4.3179 - val_accuracy: 0.3621\n",
            "Epoch 709/1000\n",
            " - 7s - loss: 0.4436 - accuracy: 0.8922 - val_loss: 5.1467 - val_accuracy: 0.3713\n",
            "Epoch 710/1000\n",
            " - 7s - loss: 0.3531 - accuracy: 0.9118 - val_loss: 4.1934 - val_accuracy: 0.3658\n",
            "Epoch 711/1000\n",
            " - 7s - loss: 0.4844 - accuracy: 0.8762 - val_loss: 3.5487 - val_accuracy: 0.3989\n",
            "Epoch 712/1000\n",
            " - 7s - loss: 0.4356 - accuracy: 0.8995 - val_loss: 4.1266 - val_accuracy: 0.3603\n",
            "Epoch 713/1000\n",
            " - 7s - loss: 0.4644 - accuracy: 0.8885 - val_loss: 5.0905 - val_accuracy: 0.3732\n",
            "Epoch 714/1000\n",
            " - 7s - loss: 0.4806 - accuracy: 0.9081 - val_loss: 4.4598 - val_accuracy: 0.3438\n",
            "Epoch 715/1000\n",
            " - 8s - loss: 0.5396 - accuracy: 0.8738 - val_loss: 4.7151 - val_accuracy: 0.3585\n",
            "Epoch 716/1000\n",
            " - 8s - loss: 0.6079 - accuracy: 0.8664 - val_loss: 5.1721 - val_accuracy: 0.3217\n",
            "Epoch 717/1000\n",
            " - 8s - loss: 0.3970 - accuracy: 0.9056 - val_loss: 4.0072 - val_accuracy: 0.3603\n",
            "Epoch 718/1000\n",
            " - 10s - loss: 0.4753 - accuracy: 0.8860 - val_loss: 4.6666 - val_accuracy: 0.3438\n",
            "Epoch 719/1000\n",
            " - 9s - loss: 0.4387 - accuracy: 0.9069 - val_loss: 4.0024 - val_accuracy: 0.3529\n",
            "Epoch 720/1000\n",
            " - 7s - loss: 0.4355 - accuracy: 0.9032 - val_loss: 4.2496 - val_accuracy: 0.3585\n",
            "Epoch 721/1000\n",
            " - 7s - loss: 0.4097 - accuracy: 0.9081 - val_loss: 4.0659 - val_accuracy: 0.3493\n",
            "Epoch 722/1000\n",
            " - 7s - loss: 0.3925 - accuracy: 0.9167 - val_loss: 4.0106 - val_accuracy: 0.3548\n",
            "Epoch 723/1000\n",
            " - 7s - loss: 0.4132 - accuracy: 0.8934 - val_loss: 3.8293 - val_accuracy: 0.3364\n",
            "Epoch 724/1000\n",
            " - 7s - loss: 0.4141 - accuracy: 0.9056 - val_loss: 4.7699 - val_accuracy: 0.3640\n",
            "Epoch 725/1000\n",
            " - 7s - loss: 0.3614 - accuracy: 0.9252 - val_loss: 4.2907 - val_accuracy: 0.3456\n",
            "Epoch 726/1000\n",
            " - 7s - loss: 0.4383 - accuracy: 0.8873 - val_loss: 4.7789 - val_accuracy: 0.3456\n",
            "Epoch 727/1000\n",
            " - 8s - loss: 0.5282 - accuracy: 0.8775 - val_loss: 4.7083 - val_accuracy: 0.3529\n",
            "Epoch 728/1000\n",
            " - 8s - loss: 0.4615 - accuracy: 0.8995 - val_loss: 4.1382 - val_accuracy: 0.3493\n",
            "Epoch 729/1000\n",
            " - 7s - loss: 0.3940 - accuracy: 0.9118 - val_loss: 4.8121 - val_accuracy: 0.3529\n",
            "Epoch 730/1000\n",
            " - 7s - loss: 0.3513 - accuracy: 0.9167 - val_loss: 4.1514 - val_accuracy: 0.3309\n",
            "Epoch 731/1000\n",
            " - 7s - loss: 0.5034 - accuracy: 0.8775 - val_loss: 4.9395 - val_accuracy: 0.3382\n",
            "Epoch 732/1000\n",
            " - 7s - loss: 0.4144 - accuracy: 0.9056 - val_loss: 4.3185 - val_accuracy: 0.3327\n",
            "Epoch 733/1000\n",
            " - 7s - loss: 0.5062 - accuracy: 0.8885 - val_loss: 4.8621 - val_accuracy: 0.3438\n",
            "Epoch 734/1000\n",
            " - 7s - loss: 0.4589 - accuracy: 0.9007 - val_loss: 3.8126 - val_accuracy: 0.3585\n",
            "Epoch 735/1000\n",
            " - 7s - loss: 0.4061 - accuracy: 0.9056 - val_loss: 4.6725 - val_accuracy: 0.3548\n",
            "Epoch 736/1000\n",
            " - 7s - loss: 0.3884 - accuracy: 0.9203 - val_loss: 4.4737 - val_accuracy: 0.3493\n",
            "Epoch 737/1000\n",
            " - 7s - loss: 0.4803 - accuracy: 0.8934 - val_loss: 3.8090 - val_accuracy: 0.3493\n",
            "Epoch 738/1000\n",
            " - 7s - loss: 0.4101 - accuracy: 0.8958 - val_loss: 3.8406 - val_accuracy: 0.3732\n",
            "Epoch 739/1000\n",
            " - 7s - loss: 0.3836 - accuracy: 0.9081 - val_loss: 6.3405 - val_accuracy: 0.3125\n",
            "Epoch 740/1000\n",
            " - 7s - loss: 0.3433 - accuracy: 0.9203 - val_loss: 5.0344 - val_accuracy: 0.3493\n",
            "Epoch 741/1000\n",
            " - 7s - loss: 0.4253 - accuracy: 0.9081 - val_loss: 4.5840 - val_accuracy: 0.3603\n",
            "Epoch 742/1000\n",
            " - 7s - loss: 0.4216 - accuracy: 0.9032 - val_loss: 4.2149 - val_accuracy: 0.3382\n",
            "Epoch 743/1000\n",
            " - 7s - loss: 0.3903 - accuracy: 0.9007 - val_loss: 4.9185 - val_accuracy: 0.3290\n",
            "Epoch 744/1000\n",
            " - 7s - loss: 0.5229 - accuracy: 0.8701 - val_loss: 3.8821 - val_accuracy: 0.3640\n",
            "Epoch 745/1000\n",
            " - 7s - loss: 0.4516 - accuracy: 0.8958 - val_loss: 4.9001 - val_accuracy: 0.3364\n",
            "Epoch 746/1000\n",
            " - 7s - loss: 0.5679 - accuracy: 0.8775 - val_loss: 4.4132 - val_accuracy: 0.3787\n",
            "Epoch 747/1000\n",
            " - 7s - loss: 0.5185 - accuracy: 0.8713 - val_loss: 4.8628 - val_accuracy: 0.3493\n",
            "Epoch 748/1000\n",
            " - 7s - loss: 0.3575 - accuracy: 0.9130 - val_loss: 4.8230 - val_accuracy: 0.3640\n",
            "Epoch 749/1000\n",
            " - 7s - loss: 0.4008 - accuracy: 0.9069 - val_loss: 4.1839 - val_accuracy: 0.3640\n",
            "Epoch 750/1000\n",
            " - 7s - loss: 0.4642 - accuracy: 0.8983 - val_loss: 4.4091 - val_accuracy: 0.3566\n",
            "Epoch 751/1000\n",
            " - 7s - loss: 0.4831 - accuracy: 0.8860 - val_loss: 4.2020 - val_accuracy: 0.3474\n",
            "Epoch 752/1000\n",
            " - 7s - loss: 0.4905 - accuracy: 0.8799 - val_loss: 4.4742 - val_accuracy: 0.3419\n",
            "Epoch 753/1000\n",
            " - 7s - loss: 0.4768 - accuracy: 0.8848 - val_loss: 4.0426 - val_accuracy: 0.3566\n",
            "Epoch 754/1000\n",
            " - 7s - loss: 0.3582 - accuracy: 0.9105 - val_loss: 4.9147 - val_accuracy: 0.3585\n",
            "Epoch 755/1000\n",
            " - 7s - loss: 0.4587 - accuracy: 0.8787 - val_loss: 6.0231 - val_accuracy: 0.3493\n",
            "Epoch 756/1000\n",
            " - 7s - loss: 0.4736 - accuracy: 0.8885 - val_loss: 4.1676 - val_accuracy: 0.3585\n",
            "Epoch 757/1000\n",
            " - 7s - loss: 0.4571 - accuracy: 0.9020 - val_loss: 4.7182 - val_accuracy: 0.3566\n",
            "Epoch 758/1000\n",
            " - 8s - loss: 0.4392 - accuracy: 0.8983 - val_loss: 4.9265 - val_accuracy: 0.3493\n",
            "Epoch 759/1000\n",
            " - 8s - loss: 0.5142 - accuracy: 0.8897 - val_loss: 4.1926 - val_accuracy: 0.3640\n",
            "Epoch 760/1000\n",
            " - 8s - loss: 0.4286 - accuracy: 0.9093 - val_loss: 3.9636 - val_accuracy: 0.3529\n",
            "Epoch 761/1000\n",
            " - 7s - loss: 0.4845 - accuracy: 0.8922 - val_loss: 4.5201 - val_accuracy: 0.3199\n",
            "Epoch 762/1000\n",
            " - 7s - loss: 0.4420 - accuracy: 0.8885 - val_loss: 3.7678 - val_accuracy: 0.3750\n",
            "Epoch 763/1000\n",
            " - 7s - loss: 0.4121 - accuracy: 0.9069 - val_loss: 3.9530 - val_accuracy: 0.3640\n",
            "Epoch 764/1000\n",
            " - 7s - loss: 0.4522 - accuracy: 0.9081 - val_loss: 4.2970 - val_accuracy: 0.3382\n",
            "Epoch 765/1000\n",
            " - 8s - loss: 0.5509 - accuracy: 0.8762 - val_loss: 4.4362 - val_accuracy: 0.3364\n",
            "Epoch 766/1000\n",
            " - 8s - loss: 0.4787 - accuracy: 0.8971 - val_loss: 4.5886 - val_accuracy: 0.3640\n",
            "Epoch 767/1000\n",
            " - 8s - loss: 0.4903 - accuracy: 0.8848 - val_loss: 4.3933 - val_accuracy: 0.3456\n",
            "Epoch 768/1000\n",
            " - 7s - loss: 0.4962 - accuracy: 0.8922 - val_loss: 4.0242 - val_accuracy: 0.3493\n",
            "Epoch 769/1000\n",
            " - 8s - loss: 0.3675 - accuracy: 0.9179 - val_loss: 4.4264 - val_accuracy: 0.3511\n",
            "Epoch 770/1000\n",
            " - 8s - loss: 0.4166 - accuracy: 0.9093 - val_loss: 4.4872 - val_accuracy: 0.3493\n",
            "Epoch 771/1000\n",
            " - 7s - loss: 0.4749 - accuracy: 0.9007 - val_loss: 3.6901 - val_accuracy: 0.3676\n",
            "Epoch 772/1000\n",
            " - 7s - loss: 0.3860 - accuracy: 0.9093 - val_loss: 3.8886 - val_accuracy: 0.3695\n",
            "Epoch 773/1000\n",
            " - 7s - loss: 0.4504 - accuracy: 0.8897 - val_loss: 3.9364 - val_accuracy: 0.3585\n",
            "Epoch 774/1000\n",
            " - 7s - loss: 0.3586 - accuracy: 0.9203 - val_loss: 4.6795 - val_accuracy: 0.3511\n",
            "Epoch 775/1000\n",
            " - 7s - loss: 0.3310 - accuracy: 0.9252 - val_loss: 5.2489 - val_accuracy: 0.3456\n",
            "Epoch 776/1000\n",
            " - 7s - loss: 0.4384 - accuracy: 0.8922 - val_loss: 5.7709 - val_accuracy: 0.3364\n",
            "Epoch 777/1000\n",
            " - 7s - loss: 0.4704 - accuracy: 0.8946 - val_loss: 4.0393 - val_accuracy: 0.3676\n",
            "Epoch 778/1000\n",
            " - 7s - loss: 0.4587 - accuracy: 0.8934 - val_loss: 4.2387 - val_accuracy: 0.3566\n",
            "Epoch 779/1000\n",
            " - 8s - loss: 0.5546 - accuracy: 0.8848 - val_loss: 5.6480 - val_accuracy: 0.3529\n",
            "Epoch 780/1000\n",
            " - 7s - loss: 0.5106 - accuracy: 0.8922 - val_loss: 5.1270 - val_accuracy: 0.3474\n",
            "Epoch 781/1000\n",
            " - 7s - loss: 0.4663 - accuracy: 0.8983 - val_loss: 4.4510 - val_accuracy: 0.3621\n",
            "Epoch 782/1000\n",
            " - 7s - loss: 0.3656 - accuracy: 0.9203 - val_loss: 4.1463 - val_accuracy: 0.3695\n",
            "Epoch 783/1000\n",
            " - 7s - loss: 0.4384 - accuracy: 0.8934 - val_loss: 4.3264 - val_accuracy: 0.3658\n",
            "Epoch 784/1000\n",
            " - 7s - loss: 0.4111 - accuracy: 0.9069 - val_loss: 4.2905 - val_accuracy: 0.3401\n",
            "Epoch 785/1000\n",
            " - 7s - loss: 0.4297 - accuracy: 0.8946 - val_loss: 4.5900 - val_accuracy: 0.3438\n",
            "Epoch 786/1000\n",
            " - 7s - loss: 0.3836 - accuracy: 0.9130 - val_loss: 5.4585 - val_accuracy: 0.3787\n",
            "Epoch 787/1000\n",
            " - 7s - loss: 0.4797 - accuracy: 0.8811 - val_loss: 5.7133 - val_accuracy: 0.3658\n",
            "Epoch 788/1000\n",
            " - 7s - loss: 0.4228 - accuracy: 0.9032 - val_loss: 5.0882 - val_accuracy: 0.3327\n",
            "Epoch 789/1000\n",
            " - 7s - loss: 0.4076 - accuracy: 0.9044 - val_loss: 4.2286 - val_accuracy: 0.3511\n",
            "Epoch 790/1000\n",
            " - 7s - loss: 0.6150 - accuracy: 0.8676 - val_loss: 5.1775 - val_accuracy: 0.3456\n",
            "Epoch 791/1000\n",
            " - 8s - loss: 0.4500 - accuracy: 0.8934 - val_loss: 3.8606 - val_accuracy: 0.3585\n",
            "Epoch 792/1000\n",
            " - 7s - loss: 0.4981 - accuracy: 0.8922 - val_loss: 4.7038 - val_accuracy: 0.3419\n",
            "Epoch 793/1000\n",
            " - 7s - loss: 0.3672 - accuracy: 0.9191 - val_loss: 6.9416 - val_accuracy: 0.3438\n",
            "Epoch 794/1000\n",
            " - 7s - loss: 0.4534 - accuracy: 0.8811 - val_loss: 5.0873 - val_accuracy: 0.3493\n",
            "Epoch 795/1000\n",
            " - 7s - loss: 0.4698 - accuracy: 0.9020 - val_loss: 5.8656 - val_accuracy: 0.3548\n",
            "Epoch 796/1000\n",
            " - 7s - loss: 0.4146 - accuracy: 0.9020 - val_loss: 6.3182 - val_accuracy: 0.3585\n",
            "Epoch 797/1000\n",
            " - 7s - loss: 0.4128 - accuracy: 0.8958 - val_loss: 4.8196 - val_accuracy: 0.3493\n",
            "Epoch 798/1000\n",
            " - 7s - loss: 0.4348 - accuracy: 0.9007 - val_loss: 5.3236 - val_accuracy: 0.3511\n",
            "Epoch 799/1000\n",
            " - 7s - loss: 0.3844 - accuracy: 0.9056 - val_loss: 5.2649 - val_accuracy: 0.3603\n",
            "Epoch 800/1000\n",
            " - 11s - loss: 0.4933 - accuracy: 0.8873 - val_loss: 4.2848 - val_accuracy: 0.3603\n",
            "Epoch 801/1000\n",
            " - 8s - loss: 0.3750 - accuracy: 0.9179 - val_loss: 6.5852 - val_accuracy: 0.3438\n",
            "Epoch 802/1000\n",
            " - 7s - loss: 0.4275 - accuracy: 0.8983 - val_loss: 4.7967 - val_accuracy: 0.3640\n",
            "Epoch 803/1000\n",
            " - 7s - loss: 0.3972 - accuracy: 0.9056 - val_loss: 3.8222 - val_accuracy: 0.3640\n",
            "Epoch 804/1000\n",
            " - 7s - loss: 0.4297 - accuracy: 0.8958 - val_loss: 4.8757 - val_accuracy: 0.3419\n",
            "Epoch 805/1000\n",
            " - 7s - loss: 0.3410 - accuracy: 0.9265 - val_loss: 4.9144 - val_accuracy: 0.3419\n",
            "Epoch 806/1000\n",
            " - 7s - loss: 0.3933 - accuracy: 0.9093 - val_loss: 4.4145 - val_accuracy: 0.3529\n",
            "Epoch 807/1000\n",
            " - 7s - loss: 0.4300 - accuracy: 0.9093 - val_loss: 4.0689 - val_accuracy: 0.3566\n",
            "Epoch 808/1000\n",
            " - 7s - loss: 0.4849 - accuracy: 0.9007 - val_loss: 4.3760 - val_accuracy: 0.3346\n",
            "Epoch 809/1000\n",
            " - 7s - loss: 0.6009 - accuracy: 0.8676 - val_loss: 4.8172 - val_accuracy: 0.3382\n",
            "Epoch 810/1000\n",
            " - 7s - loss: 0.4481 - accuracy: 0.8922 - val_loss: 4.3600 - val_accuracy: 0.3493\n",
            "Epoch 811/1000\n",
            " - 8s - loss: 0.4368 - accuracy: 0.8958 - val_loss: 4.8525 - val_accuracy: 0.3235\n",
            "Epoch 812/1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K33NXOQLDOxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(fit.history)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fit.history['loss'])\n",
        "plt.plot(fit.history['val_loss'])\n",
        "plt.plot(fit.history['accuracy'])\n",
        "plt.plot(fit.history['val_accuracy'])\n",
        "plt.title('model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "print(\"The training score is \",np.min(fit.history['loss']),np.max(fit.history['accuracy']))\n",
        "print(\"The test score is \",np.min(fit.history['val_loss']),np.max(fit.history['val_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1j7pdzTDPfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWi-soR-KiCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(input_data, target_data, test_size=0.25)\n",
        "print(\"Building network.\")\n",
        "model = km.Sequential()\n",
        "\n",
        "# Add a 2D convolution layer, with numfm feature maps.\n",
        "model.add(kl.Conv2D(numfm, kernel_size = (5, 5),\n",
        "                    input_shape = (50,50,1), \n",
        "                    activation = 'relu',name='input'))\n",
        "\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "\n",
        "model.add(kl.Conv2D(numfm * 2, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "\n",
        "model.add(kl.Conv2D(numfm * 4, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "# Convert the network from 2D to 1D.\n",
        "model.add(kl.Conv2D(numfm * 6, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "# Convert the network from 2D to 1D.\n",
        "\n",
        "model.add(kl.Flatten())\n",
        "\n",
        "# Add a fully-connected layer.\n",
        "model.add(kl.Dense(numnodes,\n",
        "                   activation = 'tanh'))\n",
        "# # Add dropout to the hidden layer.\n",
        "model.add(kl.Dropout(0.4))\n",
        "# # Add batch normalization.\n",
        "# model.add(kl.BatchNormalization())\n",
        "# Add the output layer.\n",
        "model.add(kl.Dense(output_size, activation = 'softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPt0EdjC04a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1I2lV9AeZ0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.optimizers as op\n",
        "(trainX, testX, trainY, testY) = train_test_split(input_data, target_data, test_size=0.25)\n",
        "print(\"Building network.\")\n",
        "numfm=100\n",
        "model = km.Sequential()\n",
        "\n",
        "# Add a 2D convolution layer, with numfm feature maps.\n",
        "model.add(kl.Conv2D(numfm, kernel_size = (5, 5),\n",
        "                    input_shape = (50,50,1), \n",
        "                    activation = 'relu',name='input'))\n",
        "\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "\n",
        "model.add(kl.Conv2D(numfm, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "\n",
        "model.add(kl.Conv2D(numfm, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "# Convert the network from 2D to 1D.\n",
        "model.add(kl.Conv2D(numfm, kernel_size = (3, 3),\n",
        "                    activation = 'relu'))\n",
        "# Add a max pooling layer.\n",
        "model.add(kl.MaxPooling2D(pool_size = (2, 2),\n",
        "                          strides = (2, 2)))\n",
        "# Convert the network from 2D to 1D.\n",
        "\n",
        "model.add(kl.Flatten())\n",
        "\n",
        "# Add a fully-connected layer.\n",
        "model.add(kl.Dense(numnodes,\n",
        "                   activation = 'tanh'))\n",
        "# # Add dropout to the hidden layer.\n",
        "model.add(kl.BatchNormalization())\n",
        "model.add(kl.Dropout(0.40,name = 'dropout1'))\n",
        "# # Add batch normalization.\n",
        "# model.add(kl.BatchNormalization())\n",
        "# Add the output layer.\n",
        "model.add(kl.Dense(output_size, activation = 'softmax'))\n",
        "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate=1e-2,\n",
        "#     decay_steps=10000,\n",
        "#     decay_rate=0.9)\n",
        "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "model.compile( optimizer=op.rmsprop(lr=0.001), metrics = ['accuracy'], loss = \"categorical_crossentropy\")\n",
        "#print(trainY.shape)\n",
        "print(\"Training network.\") \n",
        "# input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)\n",
        "fit = model.fit(trainX,trainY, epochs = 1000, batch_size = 200, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYFWlejjRgnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.regularizers as kr\n",
        "import keras.optimizers as op\n",
        "print(\"Building network.\")\n",
        "model1 = km.Sequential()\n",
        "numnodes=32\n",
        "# Add a 2D convolution layer, with numfm feature maps.\n",
        "lam=0.0\n",
        "model1.add(kl.Dense(numnodes,input_dim = 2500, name = 'hidden',activation = 'relu',kernel_regularizer = kr.l2(lam)))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.25,name = 'dropout1'))\n",
        "model1.add(kl.Dense(numnodes*2,name = 'hidden1',activation = 'relu',kernel_regularizer = kr.l2(lam)))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.25,name = 'dropout2'))\n",
        "model1.add(kl.Dense(numnodes*4,name = 'hidden2',activation = 'relu',kernel_regularizer = kr.l2(lam)))\n",
        "model1.add(kl.BatchNormalization())\n",
        "model1.add(kl.Dropout(0.25,name = 'dropout3'))\n",
        "# model1.add(kl.Dense(numnodes,name = 'hidden3',activation = 'relu',kernel_regularizer = kr.l2(lam)))\n",
        "# model1.add(kl.BatchNormalization())\n",
        "# model1.add(kl.Dropout(0.25,name = 'dropout4'))\n",
        "model1.add(kl.Dense(17, name = 'output',activation = 'softmax',kernel_regularizer = kr.l2(lam)))\n",
        "\n",
        "trainX= trainX.reshape(trainX.shape[0],2500)\n",
        "testX= testX.reshape(testX.shape[0],2500)\n",
        "model1.output_shape\n",
        "#print(model.summary())\n",
        "model1.compile( optimizer=op.rmsprop(lr=0.001), metrics = ['accuracy'], loss = \"categorical_crossentropy\")\n",
        "#print(trainY.shape)\n",
        "print(\"Training network.\") \n",
        "# input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)\n",
        "fit = model1.fit(trainX,trainY, epochs = 300, batch_size = 5, verbose = 2, validation_data=(testX,testY), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVmh_wuXWX_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(fit.history)\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(fit.history['loss'])\n",
        "plt.plot(fit.history['accuracy'])\n",
        "plt.plot(fit.history['val_accuracy'])\n",
        "plt.title('model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "print(\"The training score is \",np.min(fit.history['loss']),np.max(fit.history['accuracy']))\n",
        "print(\"The test score is \",np.min(fit.history['val_loss']),np.max(fit.history['val_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmUFBXAIKiCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.output_shape\n",
        "# #print(model.summary())\n",
        "# model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = \"categorical_crossentropy\")\n",
        "# #print(trainY.shape)\n",
        "# print(\"Training network.\")\n",
        "# # input_data=input_data_processed.reshape(input_data_processed.shape[0],input_dim)\n",
        "# fit = model.fit(trainX,trainY, epochs = 1000, batch_size = 5, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrX88-oCKiCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM-Fam7oKiCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsP4iulSKiC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmaQTJSKiC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################\n",
        "\n",
        "#tf.reset_default_graph()\n",
        "\n",
        "# 2) Changing input shape from 1 channel to 3 channel\n",
        "convnet = input_data(shape=[None,IMG_SIZE,IMG_SIZE,3],name='input')\n",
        "\n",
        "convnet = kl.conv_2d(convnet,32,2,activation='relu')\n",
        "convnet = kl.max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet,64,2,activation='relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "\n",
        "convnet = conv_2d(convnet,32,2,activation='relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet,64,2,activation='relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet,32,2,activation='relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet,64,2,activation='relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = fully_connected(convnet,1024,activation='relu')\n",
        "convnet = dropout(convnet,0.8)\n",
        "\n",
        "\n",
        "convnet = fully_connected(convnet,2,activation='softmax')\n",
        "convnet = regression(convnet,\n",
        "                 optimizer='adam',\n",
        "                 learning_rate= LR,\n",
        "                 loss='categorical_crossentropy',\n",
        "                 name='targets')\n",
        "\n",
        "model = tflearn.DNN(convnet)\n",
        "\n",
        "\n",
        "X=trainX\n",
        "Y=trainY\n",
        "test_x=testX\n",
        "test_y=testY\n",
        "# # 3) Changing training data shape from 1 channel to 3 channel\n",
        "# X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "# Y = np.array([i[1] for i in train])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX0F9DFxKiDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGNiz02aKiDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDotES8KiDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crz0wcKCKiDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYbhlE27KiDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g6o7dFcKiEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDqtZ25KiEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhmaVPzKiEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhXI58PnKiEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPt0VufjKiEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2grss88zKiEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuWqP4hAKiE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxCQHjaqKiE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkkAIw0kKiFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ehk8LUKiFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKusRu20KiFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-gHu1cOKiFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhppVzP0KiFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}